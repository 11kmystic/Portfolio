---
title: "Initial Models"
author: "Kevin"
date: "2024-03-15"
output:
  rmdformats::readthedown:
  self_contained: true
  thumbnails: true
  lightbox: true
  gallery: false
  highlight: tango
  toc_float: true
  toc_depth: 2
---

```{r setup, include=FALSE}
library(glue)
library(ggplot2)
library(corrplot)
library(tidyverse)
library(data.table)
library(stringr)
```
# Corplots

```{r}
seph <- read.csv("sephora_data_clean.csv", header = TRUE)
```

## Overall Corrplot

First I'd like to make a corrplot. Columns 22:71 contain the binary ingredient classifications

```{r}
ingredients <- colnames(seph)[22:71]
seph_in <- seph[, which(names(seph) %in% ingredients)]
# Column 36 is WAAAY too long. Let's fix thst
colnames(seph_in)[36] <- "Talc"
head(seph_in,10)
phi <- cor(seph_in, method = "pearson")
# corrplot.mixed(phi, order = 'AOE')
heatmap(phi, col = colorRampPalette(c("blue", "white", "red"))(100))
```
Very uninformative, so let's try again for the top 10 ingredients. I'm making a function to do so. To investigate a range like top 25-35, we'll need to modify the dataframe being fed in

## Corplots broken up

```{r cars}
# This function creates a corrplot based off inredients in our dataframe, 
corrplot_range <- function(df, top=10, order = "AOE"){
  names <- colnames(df)[1:top]
  df_top <- df[, which(names(df) %in% names)]
  phi <- cor(df_top, method = "pearson")
  corrplot.mixed(phi, order = order)
  
  return()
}

corrplot_range(seph_in, 15)
corrplot_range(seph_in[, 16:25], 10)
corrplot_range(seph_in[, 26:35], 10)
corrplot_range(seph_in[, 36:50], 15)
```
Here we see the first 2 ingredients, limonene and linanool have a relatively high correlation at 0.69. Which is still lower the the general cutoff of 0.8.Though I want to keep it.

The last 26-50 ingredients are so ridiculously correlated with each other. we can just get rid of them

```{r}
seph_in_short <- seph_in[, 1:26]
corrplot_range(seph_in_short, 26)
phi <- cor(seph_in_short, method = "pearson")
```
It's a little hard to see here, but Triclosan and mineral Oil have correlations of over 0.9 with each other and another variable. So we can get rid of those.

## Filetered Corrplot

```{r}
excess <- c("Mineral.Oil", "Triclosan")
seph_in_short <-  seph_in_short[, -which(names(seph_in_short) %in% excess)]
corrplot_range(seph_in_short, 24)
phi <-cor(seph_in_short, method = "pearson")
```
This looks much better and everything is below our threshold of 0.8! How wonderful! I'll make a df of those ingredients with everything else.

```{r}
sepho <- seph[, 1:20] # Will remove list of ingredients, but keeps if ingredients are known
sephora <- cbind(sepho, seph_in_short)
head(sephora)
```


# Average Price per Category

I was curious about average price of each category, as opposed to summing them up, so here that is. First let's rerun Revathy's code to have something to compare too

## Total Sum per Category

```{r}
price_sorted_category <- sephora %>%
  group_by(category) %>%
  summarise(price = sum(price)) %>%
  arrange(desc(price)) %>%
  slice_head(n = 10)
price_sorted_category

ggplot(price_sorted_category, aes(x=category, y=price, fill=category)) +
geom_bar(stat="identity") +
scale_fill_brewer(palette="Spectral") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
labs(x="Category", y="Total Price")
```

## Mean per category

```{r}
price_sorted_category <- sephora %>%
  group_by(category) %>%
  summarise(price = mean(price)) %>%
  arrange(desc(price)) %>%
  slice_head(n = 10)
price_sorted_category

ggplot(price_sorted_category, aes(x=category, y=price, fill=category)) +
geom_bar(stat="identity") +
scale_fill_brewer(palette="Spectral") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
labs(x="Category", y="Average Price")
```
Scents being expensive makes sense. There are tons of $100 perfumes. Interestingly enough, there is enough cheap skincare to bring down the mean, even though it had such a  high total earlier in our EDA.

## Log price Boxplots

I also wanted to look at the log range of each one.

```{r}
ggplot(sephora, aes(x=category, y=log(price), fill= category)) + 
  geom_boxplot()
```

# Oulier Removal

From here, we can see that we could benefit from removing outliers. (This categorization was also my doing, so there's that. I'm impressed it even looks normalish anyway) What would constitute an outlier? Anything 3 or more z-scores away from the log price of the mean. Let's clean that.

## Setting z-score

```{r}
sephora$log_price <- log(sephora$price)

sephora_z <- sephora %>%
  group_by(category) %>%
  mutate(zscore = scale(log_price)) %>%
  filter(abs(zscore) < 3) %>%
  ungroup()

ggplot(sephora_z, aes(x=category, y=log(price), fill= category)) + 
  geom_boxplot()
```
We can see that made a minor difference in things like amakeup and haircare, (which essentially it should do)

Finally, let's make a new csv just like that. I am removing the z-scores and keeping the log prices.

# Making a New CSV

```{r}
sephora <- sephora_z[, 1:45]
write.csv(sephora, "sephora_clean_v2.csv", row.names=FALSE)
```

